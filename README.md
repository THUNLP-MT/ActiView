# ActiView: Evaluating Active Perception Ability for Multimodal Large Language Models
[**ğŸŒ Homepage**](https://wangphoebe.github.io/actiview_homepage/)| [**ğŸ“– arXiv**](https://arxiv.org/pdf/2410.04659.pdf) 

Coming soon â³ğŸ”œ

- ğŸš§ We will release our benchmark and evaluation toolkit ASAP.
  
- ğŸ“¨ If you have any questions regarding the data and evaluation scripts when they are temporarily unavailable, please contact [w.ziyue1010@gmail.com](mailto:w.ziyue1010@gmail.com).
  
## Timeline

<font color=Blue>ğŸ“¢ [2024-10-20] Benchmark and evaluation toolkit (for API-based models) released [TBD]</font>

ğŸ“¢ [2024-10-14] Homepage released.

ğŸ“¢ [2024-10-07] Paper and repo released.  

## Project Overview
This repository contains all the necessary materials, including:
- **Datasets** for active perception evaluation
- **Toolkits** for model evaluation
- **Results** and analysis from the paper

## Citation
If you find our project useful, please consider citing:
```
@misc{wang2024activiewevaluatingactiveperception,
      title={ActiView: Evaluating Active Perception Ability for Multimodal Large Language Models}, 
      author={Ziyue Wang and Chi Chen and Fuwen Luo and Yurui Dong and Yuanchi Zhang and Yuzhuang Xu and Xiaolong Wang and Peng Li and Yang Liu},
      year={2024},
      eprint={2410.04659},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.04659}, 
}
```
